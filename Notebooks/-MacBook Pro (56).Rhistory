replace = FALSE)
# Nombres de las columnas
names(raw_data)
# Visualizamos el dataset
head(raw_data, 10)
tail(raw_data, 10)
# Estructura de los datos
str(raw_data)
# Dimensión de la base de datos
dim(raw_data)
# Comprobamos que no tenemos nulos
sum(is.na(raw_data))
# Probamos un cluster por intensidades para forzar que cuanta menos experiencia mas crashes
data <- raw_data %>%
select(pesopot, edad, ant_lic, intensidad_uso_diario)
# Comprobamos la dimension...
dim(data)
# Creamos una muestra con la que lanzar el número óptimo de clusters
data_sample <- sample_n(data,
size = 10000,
replace = FALSE)
# Calculamos la distancia de de la muestra
diss_euclidean_sample <- daisy(data_sample, metric = "euclidean", stand = FALSE)
silhouette <- c()
silhouette = c(silhouette, NA)
for(i in 2:5){
pam_clusters = pam(as.matrix(diss_euclidean_sample),
diss = TRUE,
k = i)
silhouette = c(silhouette ,pam_clusters$silinfo$avg.width)
}
plot(1:5, silhouette,
xlab = "Clusters",
ylab = "Silhouette Width")
lines(1:5, silhouette)
# Ploteamos los clusters
pam_2G <- eclust(data, FUNcluster = "pam", stand = TRUE, hc_metric = "euclidean", k = 2, seed = 1322)
# Cluster con geom = "point" para que no salgan las etiquetas de las observaciones
fviz_cluster(pam_2G, geom = "point") +
labs(title = "PAM clustering")
# Silueta
fviz_silhouette(pam_2G)
# Clusters
Grupos_variables <- pam_2G$clustering
# Generación del dataset
data_cluster <- as.data.frame(cbind(Grupos_variables, raw_data))
# Seleccionamos el primer grupo
grupo1 <- data_cluster %>% filter(Grupos_variables == 2)
# Realizamos un summary
summary(grupo1)
# Seleccionamos el primer grupo
grupo2 <- data_cluster %>% filter(Grupos_variables == 2)
# Realizamos un summary
summary(grupo2)
# Guardamos el nuevo dataset
write.csv(x = data_cluster,
file = "../00_data/3_clusters/data_clustering.csv")
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(cluster = as.factor(pam_grupos$clustering)) %>%
ggplot(aes(x = ant_lic, fill = cluster)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Grupos por la antiguedad de licencia")
# Seleccionamos el primer grupo
grupo1 <- data_cluster %>% filter(Grupos_variables == 1)
# Realizamos un summary
summary(grupo1)
# Seleccionamos el primer grupo
grupo2 <- data_cluster %>% filter(Grupos_variables == 2)
# Realizamos un summary
summary(grupo2)
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(cluster = as.factor(pam_2G$clustering)) %>%
ggplot(aes(x = ant_lic, fill = cluster)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Grupos por la antiguedad de licencia")
# De manera tabular podemos observarlo asi
raw_data %>%
mutate(cluster = pam_2G$clustering) %>%
group_by(ant_lic, cluster) %>%
summarise(n = n(),
media_edad = mean(edad)) %>%
mutate(freq = n/sum(n))
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(crash_categorica = as.factor(crash_categorica),
cluster = as.factor(pam_2G$clustering)) %>%
filter(crash_categorica != "Ninguno") %>%
ggplot(aes(x = cluster, fill = crash_categorica)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Crashes por cluster") +
guides(fill = guide_legend(title = "Crashes discretizados"))
raw_data %>%
mutate(cluster = pam_2G$clustering) %>%
group_by(crash_categorica) %>%
summarise(media_experiencia = mean(ant_lic))
knitr::opts_chunk$set(echo = TRUE)
# Carga y limpieza de datos
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(imputeTS)
library(skimr)
# Cluster y ANACOR
library(FactoMineR)
library(factoextra)
library(clustertend)
library(NbClust)
library(cluster)
library(Rtsne)
# Semila
set.seed(1322)
# Cargamos la base de datos
data_plot <- read_csv("../00_data/2_processed/data_processed.csv")
# -----------------------------------------------------------------------------------------
# Definimos la variable
x <- data_plot$intensidad_uso_diario
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles) %>%
summarise(ant_lic_med = mean(ant_lic)) %>%
ggplot(aes(x = quintiles, y = ant_lic_med)) +
geom_line(color = "deepskyblue") +
geom_point(color = "deepskyblue") +
ggtitle("Intensidad de uso en quintiles en función de la experiencia") +
xlab("Quintiles de la intensidad de uso") +
ylab("Experiencia media (años)")
# Summary
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles) %>%
summarise(ant_lic_med = mean(ant_lic))
# ----------------------------------------------------------------------------------------------
x <- data_plot$ant_lic
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles, sexo) %>%
summarise(crashes_medios = mean(n_crashes)) %>%
ggplot(aes(x = quintiles, y = crashes_medios, group = sexo)) +
geom_line(aes(color = sexo)) +
geom_point(aes(color = sexo)) +
ggtitle("Crashes medios en función de los quintiles de la experiencia") +
xlab("Quintiles de la experiencia") +
ylab("Crashes medios")
# Summary
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles, sexo) %>%
summarise(crashes_medios = mean(n_crashes))
raw_data_original <- read_csv("../00_data/2_processed/data_processed.csv")
raw_data_original <- as.data.frame(raw_data_original)
# Creamos una muestra de 30.000
raw_data <- sample_n(raw_data_original,
size = 30000,
replace = FALSE)
# Nombres de las columnas
names(raw_data)
# Visualizamos el dataset
head(raw_data, 10)
tail(raw_data, 10)
# Estructura de los datos
str(raw_data)
# Dimensión de la base de datos
dim(raw_data)
# Comprobamos que no tenemos nulos
sum(is.na(raw_data))
# Probamos un cluster por intensidades para forzar que cuanta menos experiencia mas crashes
data <- raw_data %>%
select(pesopot, edad, ant_lic, intensidad_uso_diario)
# Comprobamos la dimension...
dim(data)
# Creamos una muestra con la que lanzar el número óptimo de clusters
data_sample <- sample_n(data,
size = 10000,
replace = FALSE)
# Calculamos la distancia de de la muestra
diss_euclidean_sample <- daisy(data_sample, metric = "euclidean", stand = FALSE)
# Ploteamos los clusters
pam_2G <- eclust(data, FUNcluster = "pam", stand = TRUE, hc_metric = "euclidean", k = 2, seed = 1322)
# Cluster con geom = "point" para que no salgan las etiquetas de las observaciones
fviz_cluster(pam_2G, geom = "point") +
labs(title = "PAM clustering")
# Silueta
fviz_silhouette(pam_2G)
# Clusters
Grupos_variables <- pam_2G$clustering
# Generación del dataset
data_cluster <- as.data.frame(cbind(Grupos_variables, raw_data))
# Seleccionamos el primer grupo
grupo1 <- data_cluster %>% filter(Grupos_variables == 1)
# Realizamos un summary
summary(grupo1)
# Seleccionamos el primer grupo
grupo2 <- data_cluster %>% filter(Grupos_variables == 2)
# Realizamos un summary
summary(grupo2)
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(cluster = as.factor(pam_2G$clustering)) %>%
ggplot(aes(x = ant_lic, fill = cluster)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Grupos por la antiguedad de licencia")
# De manera tabular podemos observarlo asi
raw_data %>%
mutate(cluster = pam_2G$clustering) %>%
group_by(ant_lic, cluster) %>%
summarise(n = n(),
media_edad = mean(edad)) %>%
mutate(freq = n/sum(n))
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(crash_categorica = as.factor(crash_categorica),
cluster = as.factor(pam_2G$clustering)) %>%
filter(crash_categorica != "Ninguno") %>%
ggplot(aes(x = cluster, fill = crash_categorica)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Crashes por cluster") +
guides(fill = guide_legend(title = "Crashes discretizados"))
raw_data %>%
mutate(cluster = pam_2G$clustering) %>%
group_by(crash_categorica) %>%
summarise(media_experiencia = mean(ant_lic))
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("data_clustering.csv")
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv.csv")
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes)
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
modelo
# Plot
rpart.plot(x = modelo)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(crash_flag = ifelse(test = 0, "no crash", "crash"))
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(crash_flag = ifelse(test = 0, "no crash", "crash"))
View(data_filter)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(crash_flag = ifelse(crash_flag == 0, "no crash", "crash"))
View(data_filter)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(crash_flag = ifelse(crash_flag == 0, "no crash", "crash"))
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
modelo
# Plot
rpart.plot(x = modelo)
summary(data_filter)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(crash_flag = as.factor(ifelse(crash_flag == 0, "no crash", "crash")))
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
modelo
# Plot
rpart.plot(x = modelo)
summary(data_filter)
View(data_filter)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(crash_flag = as.factor(ifelse(crash_flag == 0, "no crash", "crash")),
sexo = as.factor(sexo),
gpos_aut = as.factor(gpos_aut),
Grupos_variables = as.factor(Grupos_variables),
tipo_de_marca = as.factor(tipo_de_marca))
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
modelo
# Plot
rpart.plot(x = modelo)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes) %>%
mutate(
sexo = as.factor(sexo),
gpos_aut = as.factor(gpos_aut),
Grupos_variables = as.factor(Grupos_variables),
tipo_de_marca = as.factor(tipo_de_marca))
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
modelo
# Plot
rpart.plot(x = modelo)
library(rpart)
library(rpart.plot)
library(readr)
library(dplyr)
# Cargamos los datos
data <- read_csv("../00_data/3_clusters/data_clustering.csv")
data_filter <- data %>%
select(-X1, -X1_1, -cod_cpi, -crash_categorica, -n_crashes, -dias_desde_ultimo_arranque) %>%
mutate(
sexo = as.factor(sexo),
gpos_aut = as.factor(gpos_aut),
Grupos_variables = as.factor(Grupos_variables),
tipo_de_marca = as.factor(tipo_de_marca))
# Crecimiento de arbol
modelo <- rpart(crash_flag ~ ., data = data_filter)
modelo
# Plot
rpart.plot(x = modelo)
knitr::opts_chunk$set(echo = TRUE)
# Carga y limpieza de datos
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(imputeTS)
library(skimr)
# Cluster y ANACOR
library(FactoMineR)
library(factoextra)
library(clustertend)
library(NbClust)
library(cluster)
library(Rtsne)
# Semila
set.seed(1322)
# Cargamos la base de datos
data_plot <- read_csv("../00_data/2_processed/data_processed.csv")
# -----------------------------------------------------------------------------------------
# Definimos la variable
x <- data_plot$intensidad_uso_diario
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles) %>%
summarise(ant_lic_med = mean(ant_lic)) %>%
ggplot(aes(x = quintiles, y = ant_lic_med)) +
geom_line(color = "deepskyblue") +
geom_point(color = "deepskyblue") +
ggtitle("Intensidad de uso en quintiles en función de la experiencia") +
xlab("Quintiles de la intensidad de uso") +
ylab("Experiencia media (años)")
# Summary
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles) %>%
summarise(ant_lic_med = mean(ant_lic))
# ----------------------------------------------------------------------------------------------
x <- data_plot$ant_lic
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles, sexo) %>%
summarise(crashes_medios = mean(n_crashes)) %>%
ggplot(aes(x = quintiles, y = crashes_medios, group = sexo)) +
geom_line(aes(color = sexo)) +
geom_point(aes(color = sexo)) +
ggtitle("Crashes medios en función de los quintiles de la experiencia") +
xlab("Quintiles de la experiencia") +
ylab("Crashes medios")
# Summary
data_plot %>%
within(quintiles <- as.integer(cut(x, quantile(x, probs=0:5/5), include.lowest=TRUE))) %>%
group_by(quintiles, sexo) %>%
summarise(crashes_medios = mean(n_crashes))
raw_data_original <- read_csv("../00_data/2_processed/data_processed.csv")
raw_data_original <- as.data.frame(raw_data_original)
# Creamos una muestra de 30.000
raw_data <- sample_n(raw_data_original,
size = 30000,
replace = FALSE)
# Nombres de las columnas
names(raw_data)
# Visualizamos el dataset
head(raw_data, 10)
tail(raw_data, 10)
# Estructura de los datos
str(raw_data)
# Dimensión de la base de datos
dim(raw_data)
# Comprobamos que no tenemos nulos
sum(is.na(raw_data))
# Probamos un cluster por intensidades para forzar que cuanta menos experiencia mas crashes
data <- raw_data %>%
select(pesopot, edad, ant_lic, intensidad_uso_diario)
# Comprobamos la dimension...
dim(data)
# Creamos una muestra con la que lanzar el número óptimo de clusters
data_sample <- sample_n(data,
size = 10000,
replace = FALSE)
# Calculamos la distancia de de la muestra
diss_euclidean_sample <- daisy(data_sample, metric = "euclidean", stand = FALSE)
silhouette <- c()
silhouette = c(silhouette, NA)
for(i in 2:5){
pam_clusters = pam(as.matrix(diss_euclidean_sample),
diss = TRUE,
k = i)
silhouette = c(silhouette ,pam_clusters$silinfo$avg.width)
}
plot(1:5, silhouette,
xlab = "Clusters",
ylab = "Silhouette Width")
lines(1:5, silhouette)
# Ploteamos los clusters
pam_2G <- eclust(data, FUNcluster = "pam", stand = TRUE, hc_metric = "euclidean", k = 2, seed = 1322)
# Cluster con geom = "point" para que no salgan las etiquetas de las observaciones
fviz_cluster(pam_2G, geom = "point") +
labs(title = "PAM clustering")
# Silueta
fviz_silhouette(pam_2G)
# Clusters
Grupos_variables <- pam_2G$clustering
# Generación del dataset
data_cluster <- as.data.frame(cbind(Grupos_variables, raw_data))
# Seleccionamos el primer grupo
grupo1 <- data_cluster %>% filter(Grupos_variables == 1)
# Realizamos un summary
summary(grupo1)
# Seleccionamos el primer grupo
grupo2 <- data_cluster %>% filter(Grupos_variables == 2)
# Realizamos un summary
summary(grupo2)
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(cluster = as.factor(pam_2G$clustering)) %>%
ggplot(aes(x = ant_lic, fill = cluster)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Grupos por la antiguedad de licencia")
# De manera tabular podemos observarlo asi
raw_data %>%
mutate(cluster = pam_2G$clustering) %>%
group_by(ant_lic, cluster) %>%
summarise(n = n(),
media_edad = mean(edad)) %>%
mutate(freq = n/sum(n))
# Aqui podemos observar como los conductores de temprena edad están asociados al primer grupo, mientras que los más experimentados al segundo
raw_data %>%
mutate(crash_categorica = as.factor(crash_categorica),
cluster = as.factor(pam_2G$clustering)) %>%
filter(crash_categorica != "Ninguno") %>%
ggplot(aes(x = cluster, fill = crash_categorica)) +
geom_bar(aes(y = (..count..)/sum(..count..))) +
ylab("Porcentaje") +
ggtitle("Crashes por cluster") +
guides(fill = guide_legend(title = "Crashes discretizados"))
raw_data %>%
mutate(cluster = pam_2G$clustering) %>%
group_by(crash_categorica) %>%
summarise(media_experiencia = mean(ant_lic))
